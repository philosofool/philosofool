{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac0d365",
   "metadata": {},
   "source": [
    "# Oddball Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Iterator\n",
    "import json\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans, HDBSCAN    # pyright: ignore [reportAttributeAccessIssue]  HDBSCAN not recognized.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'archive/CC GENERAL.csv'\n",
    "# see https://www.kaggle.com/datasets/arjunbhasin2013/ccdata?resource=download for dataset description.\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc6f61",
   "metadata": {},
   "source": [
    "## Data Exploration and Discussion\n",
    "\n",
    "The data is very clean. Missing values are only in CREDIT_LIMIT and MINIMUM_PAYMENT, 1 and ~300 (of 8950) respectively. \n",
    "These are easy to explain: a no-limit card and card-holders with no payment history to date.\n",
    "There are some huge outliers.\n",
    "The the variables are not normally distributed; they tend to center to the left and right in histograms. \n",
    "A few have a bathtub shape.\n",
    "\n",
    "CUST_ID : Identification of Credit Card holder (Categorical)\n",
    "\n",
    "BALANCE : Balance amount left in their account to make purchases\n",
    "\n",
    "BALANCE_FREQUENCY : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n",
    "\n",
    "PURCHASES : Amount of purchases made from account\n",
    "\n",
    "ONEOFF_PURCHASES : Maximum purchase amount done in one-go\n",
    "\n",
    "INSTALLMENTS_PURCHASES : Amount of purchase done in installment\n",
    "\n",
    "CASH_ADVANCE : Cash in advance given by the user\n",
    "\n",
    "PURCHASES_FREQUENCY : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n",
    "\n",
    "ONEOFFPURCHASESFREQUENCY : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n",
    "\n",
    "PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n",
    "\n",
    "CASHADVANCEFREQUENCY : How frequently the cash in advance being paid\n",
    "\n",
    "CASHADVANCETRX : Number of Transactions made with \"Cash in Advanced\"\n",
    "\n",
    "PURCHASES_TRX : Numbe of purchase transactions made\n",
    "\n",
    "CREDIT_LIMIT : Limit of Credit Card for user\n",
    "\n",
    "PAYMENTS : Amount of Payment done by user\n",
    "\n",
    "MINIMUM_PAYMENTS : Minimum amount of payments made by user\n",
    "\n",
    "PRCFULLPAYMENT : Percent of full payment paid by user\n",
    "\n",
    "TENURE : Tenure of credit card service for user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98458387",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing Value Counts')\n",
    "pprint({key: value for key, value in df.isna().sum().items() if value > 0})\n",
    "print(\"Duplicate Record Count\")\n",
    "print(len(df) - len(df.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc56e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c1baa",
   "metadata": {},
   "source": [
    "## Evaluation Process\n",
    "\n",
    "Per my preference, I define evaluation before modeling. This is because:\n",
    "- It's a bad idea to create a model you don't know how to evaluate. It can result in deciding a model has virtues you can find rather than virtues you expect.\n",
    "- It's a good idea to have conversation about how a model will be assess before you can talk about the strengths and weakness of a model. (Teams take responsibility for what counts as good, expressing requirements, etc.)\n",
    "- Is intelletually honest about the quality of evaluation you can produce. \n",
    "(Clustering, for example, does not have an obvious right answer, but depends on application.)\n",
    "- It encourages writing flexible evalution functions, which makes model development and iteration faster in the long run. (Promotes code re-use.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_logs(new_data: dict | list | str, path: str):\n",
    "    \"\"\"Append new data to an existing json, or create one if it does not exist.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "    except FileNotFoundError:\n",
    "        data = []\n",
    "    data.append(new_data)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json.dumps(data, indent=4))\n",
    "\n",
    "def evaluate_unsupervised_clustering(model: BaseEstimator, data: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate an unsupervised clustering model using common clustering metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BaseEstimator\n",
    "        A fitted or unfitted scikit-learn compatible clustering model (e.g., KMeans, HDBSCAN).\n",
    "        The model must implement a `.fit_predict` method.\n",
    "\n",
    "    data : np.ndarray\n",
    "        The input data array of shape (n_samples, n_features) to cluster.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores : dict\n",
    "        A dictionary containing the following metrics:\n",
    "        - 'n_labels': int\n",
    "            The number of non-noise clusters found (ignores label -1).\n",
    "        - 'noise_percent': float\n",
    "            Proportion of data points labeled as noise (-1).\n",
    "        - 'silhouette_score': float\n",
    "            Silhouette score of the clustering (0 if fewer than 2 clusters).\n",
    "        - 'calinski_harabasz_score': float\n",
    "            Calinski-Harabasz index of the clustering (0 if fewer than 2 clusters).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If the model finds fewer than 2 clusters (excluding noise), the silhouette and\n",
    "    Calinski-Harabasz scores will be set to 0, as these metrics are undefined in that case.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    clustered_data = model.fit_predict(data)\n",
    "    labels = np.unique(clustered_data)\n",
    "    scores['n_labels'] = labels.size - (-1 in labels)\n",
    "    scores['noise_percent'] = np.sum((clustered_data == -1)) / clustered_data.size\n",
    "    if scores['n_labels'] > 1:\n",
    "        scores['silhouette_score'] = silhouette_score(data, clustered_data, metric='euclidean')\n",
    "        scores['calinski_harabasz_score'] = calinski_harabasz_score(data, clustered_data)\n",
    "    else:\n",
    "        scores['silhouette_score'] = 0\n",
    "        scores['calinski_harabasz_score'] = 0\n",
    "    return scores\n",
    "\n",
    "\n",
    "def test_evaluate_unsupervised_clustering():\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    model = KMeans(n_clusters=3, random_state=123)\n",
    "    data, *_ = make_blobs(random_state=567)\n",
    "\n",
    "    result = evaluate_unsupervised_clustering(model, data)\n",
    "    assert result['silhouette_score'] > 0\n",
    "    assert result['calinski_harabasz_score'] > 0\n",
    "    assert result['noise_percent'] >= 0 and result['noise_percent'] <= 1.\n",
    "    assert result['n_labels'] == 3\n",
    "\n",
    "\n",
    "test_evaluate_unsupervised_clustering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b8be0",
   "metadata": {},
   "source": [
    "## Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bddef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame, selected_columns: list[str] = []) -> np.ndarray:\n",
    "    if selected_columns:\n",
    "        df = df[selected_columns]\n",
    "    else:\n",
    "        df = df.drop(columns=['CUST_ID'])\n",
    "    data = ColumnTransformer(\n",
    "        [step for step in [\n",
    "            ('min_payment', SimpleImputer(strategy='constant', fill_value=-1.), ['MINIMUM_PAYMENTS']),\n",
    "            ('credit_limit', SimpleImputer(strategy='constant', fill_value=200_000.), ['CREDIT_LIMIT']),\n",
    "        ]\n",
    "        if step[2][0] in selected_columns or not selected_columns],\n",
    "        remainder='passthrough'\n",
    "    ).fit_transform(df)\n",
    "    return data\n",
    "\n",
    "def fit_and_evaluate_model(model: BaseEstimator, data_transform: Pipeline, df: pd.DataFrame = df):\n",
    "    data = clean_data(df)\n",
    "    transformed_data = data_transform.fit_transform(data)\n",
    "    return evaluate_unsupervised_clustering(model, transformed_data)\n",
    "\n",
    "def param_grid_to_parameters(param_grid: dict[str, list]) -> Iterator:\n",
    "    parameters = list(param_grid)\n",
    "    for param_options in itertools.product(*param_grid.values()):\n",
    "        param_spec = {parameters[i]: param_value for i, param_value in enumerate(param_options)}\n",
    "        yield param_spec\n",
    "\n",
    "def tune(model_name: str, pipeline: Pipeline, df: pd.DataFrame, param_grid: dict):\n",
    "    \"\"\"Extract parameters from a parameters grid and trained the re-parameterized model on the data in df.\"\"\"\n",
    "    parameter_grid = param_grid[model_name]\n",
    "    for parameters in param_grid_to_parameters(parameter_grid):\n",
    "        pipeline.set_params(**parameters)\n",
    "        data_transform = pipeline.named_steps['data_transform']\n",
    "        cluster_model = pipeline.named_steps['clustering']\n",
    "        scores = fit_and_evaluate_model(cluster_model, data_transform, df)\n",
    "        scores['model_name'] = model_name\n",
    "        results = {'parameters': parameters, 'scores': scores}\n",
    "        simple_logs(results, 'model_scores.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d517fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Preprocessing and Model Architecture\n",
    "# This will be passed through a tuning process, so we can mostly use default values now.\n",
    "\n",
    "data_transform_standard_pca = Pipeline([\n",
    "    ('scale_data', StandardScaler()),\n",
    "    ('PCA', PCA(n_components=4)),\n",
    "])\n",
    "data_transform_umap = Pipeline([\n",
    "    ('scale_data', StandardScaler()),\n",
    "    ('UMAP', UMAP(n_components=30)),\n",
    "])\n",
    "data_transform_robust_pca = Pipeline([\n",
    "    ('scale_data', RobustScaler()),\n",
    "    ('PCA', PCA(n_components=3)),\n",
    "])\n",
    "\n",
    "clustering_models: dict[str, Pipeline] = {\n",
    "    'kmeans_model': Pipeline([\n",
    "        ('data_transform', data_transform_standard_pca),\n",
    "        ('clustering', KMeans(n_clusters=4))\n",
    "    ]),\n",
    "    'normalize_kmeans': Pipeline([\n",
    "        ('data_transform', data_transform_standard_pca),\n",
    "        ('clustering', KMeans(n_clusters=4))\n",
    "    ]),\n",
    "    'hdb_model': Pipeline([\n",
    "        ('data_transform', data_transform_standard_pca),\n",
    "        ('clustering', HDBSCAN())\n",
    "    ]),\n",
    "    'robust_hdb_model': Pipeline([\n",
    "        ('data_transform', data_transform_robust_pca),\n",
    "        ('clustering', HDBSCAN(min_cluster_size=50))\n",
    "    ]),\n",
    "    'umap_hdb_model': Pipeline([\n",
    "        ('data_transform', data_transform_umap),\n",
    "        ('clustering', HDBSCAN(min_cluster_size=50))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "\n",
    "hdb_param_grid = {\n",
    "    'data_transform__PCA__n_components': [2, 3, 4, 5, .95],\n",
    "    'clustering__min_cluster_size': [5, 25, 40, 50, 60],\n",
    "    'clustering__min_samples': [None, 3, 7, 20],\n",
    "}\n",
    "kmeans_param_grid = {\n",
    "    'data_transform__PCA__n_components': [2, 3, 4, 5, .95],\n",
    "    'clustering__n_clusters': [2, 3, 4, 5]\n",
    "}\n",
    "umap_param_grid = {\n",
    "    'data_transform__UMAP__n_neighbors': [30],\n",
    "    'data_transform__UMAP__n_components': [2, 3],\n",
    "    'clustering__min_cluster_size': [5, 25, 40],\n",
    "    'clustering__min_samples': [None, 3, 7, 20],\n",
    "}\n",
    "\n",
    "clustering_models_params = {\n",
    "    'kmeans_model': kmeans_param_grid,\n",
    "    'normalize_kmeans': kmeans_param_grid,\n",
    "    'hdb_model': hdb_param_grid,\n",
    "    'robust_hdb_model': hdb_param_grid,\n",
    "    'umap_hdb_model': umap_param_grid\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, pipeline in clustering_models.items():\n",
    "    ...\n",
    "    # UNCOMMENT TO RUN. Takes a few minutes.\n",
    "    # tune(model_name, pipeline, df, clustering_models_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4930d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_models() -> list[dict]:\n",
    "    \"\"\"\n",
    "    Load and filter clustering model results based on quality criteria.\n",
    "\n",
    "    This function reads model evaluation results from a JSON file (`model_scores.json`)\n",
    "    and returns a list of models that meet specific quality thresholds. These thresholds\n",
    "    are used to filter out low-quality or poorly performing clustering models.\n",
    "\n",
    "    The filtering criteria are:\n",
    "    - The number of clusters (`n_labels`) is between 2 and 7 (inclusive).\n",
    "    - The proportion of noise points (`noise_percent`) is less than or equal to 0.25.\n",
    "    - The silhouette score is at least 0.3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        A list of model evaluation dictionaries that pass the quality filter.\n",
    "        Each dictionary contains a 'scores' field and other metadata.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The input file `model_scores.json` must exist in the current working directory\n",
    "    and must contain a JSON array of model evaluation results, each with a 'scores'\n",
    "    dictionary containing the keys:\n",
    "    - 'n_labels'\n",
    "    - 'noise_percent'\n",
    "    - 'silhouette_score'\n",
    "    \"\"\"\n",
    "    with open(\"model_scores.json\", 'r') as f:\n",
    "        tuning_data = json.loads(f.read())\n",
    "\n",
    "    def is_acceptable(score_data: dict) -> bool:\n",
    "        score = score_data['scores']\n",
    "        return (\n",
    "            score['n_labels'] >= 2\n",
    "            and score['n_labels'] <= 7\n",
    "            and score['noise_percent'] <= .25\n",
    "            and score['silhouette_score'] >= .3\n",
    "        )\n",
    "    return [score_data for score_data in tuning_data if is_acceptable(score_data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e5cbe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_labels</th>\n",
       "      <th>noise_percent</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>calinski_harabasz_score</th>\n",
       "      <th>model_name</th>\n",
       "      <th>data_transform__PCA__n_components</th>\n",
       "      <th>clustering__n_clusters</th>\n",
       "      <th>clustering__min_cluster_size</th>\n",
       "      <th>clustering__min_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0.039777</td>\n",
       "      <td>0.659379</td>\n",
       "      <td>1375.822506</td>\n",
       "      <td>robust_hdb_model</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>0.624716</td>\n",
       "      <td>439.578199</td>\n",
       "      <td>hdb_model</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>0.075866</td>\n",
       "      <td>0.569218</td>\n",
       "      <td>1158.880716</td>\n",
       "      <td>robust_hdb_model</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448912</td>\n",
       "      <td>5314.578994</td>\n",
       "      <td>normalize_kmeans</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443876</td>\n",
       "      <td>5315.265851</td>\n",
       "      <td>kmeans_model</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_labels  noise_percent  silhouette_score  calinski_harabasz_score  \\\n",
       "29         3       0.039777          0.659379              1375.822506   \n",
       "24         4       0.016089          0.624716               439.578199   \n",
       "32         3       0.075866          0.569218              1158.880716   \n",
       "12         3       0.000000          0.448912              5314.578994   \n",
       "1          3       0.000000          0.443876              5315.265851   \n",
       "\n",
       "          model_name  data_transform__PCA__n_components  \\\n",
       "29  robust_hdb_model                                2.0   \n",
       "24         hdb_model                                3.0   \n",
       "32  robust_hdb_model                                2.0   \n",
       "12  normalize_kmeans                                2.0   \n",
       "1       kmeans_model                                2.0   \n",
       "\n",
       "    clustering__n_clusters  clustering__min_cluster_size  \\\n",
       "29                     NaN                          25.0   \n",
       "24                     NaN                           5.0   \n",
       "32                     NaN                          40.0   \n",
       "12                     3.0                           NaN   \n",
       "1                      3.0                           NaN   \n",
       "\n",
       "    clustering__min_samples  \n",
       "29                      3.0  \n",
       "24                      NaN  \n",
       "32                      7.0  \n",
       "12                      NaN  \n",
       "1                       NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract results to a dataframe. List best models with more than 2 labels.\n",
    "acceptable_models = quality_models()\n",
    "scores = pd.DataFrame.from_records([a['scores'] | a['parameters'] for a in acceptable_models])\n",
    "scores.sort_values('silhouette_score', ascending=False).query(\"n_labels > 2\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05fd3643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_labels</th>\n",
       "      <th>noise_percent</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>calinski_harabasz_score</th>\n",
       "      <th>model_name</th>\n",
       "      <th>data_transform__PCA__n_components</th>\n",
       "      <th>clustering__n_clusters</th>\n",
       "      <th>clustering__min_cluster_size</th>\n",
       "      <th>clustering__min_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>0.008827</td>\n",
       "      <td>0.822311</td>\n",
       "      <td>972.796604</td>\n",
       "      <td>robust_hdb_model</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.799203</td>\n",
       "      <td>591.894524</td>\n",
       "      <td>hdb_model</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.785955</td>\n",
       "      <td>515.499060</td>\n",
       "      <td>hdb_model</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.755280</td>\n",
       "      <td>369.457868</td>\n",
       "      <td>hdb_model</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>1009.086536</td>\n",
       "      <td>robust_hdb_model</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_labels  noise_percent  silhouette_score  calinski_harabasz_score  \\\n",
       "35         2       0.008827          0.822311               972.796604   \n",
       "25         2       0.003575          0.799203               591.894524   \n",
       "27         2       0.004134          0.785955               515.499060   \n",
       "28         2       0.004804          0.755280               369.457868   \n",
       "33         2       0.027598          0.703180              1009.086536   \n",
       "\n",
       "          model_name  data_transform__PCA__n_components  \\\n",
       "35  robust_hdb_model                               5.00   \n",
       "25         hdb_model                               3.00   \n",
       "27         hdb_model                               4.00   \n",
       "28         hdb_model                               0.95   \n",
       "33  robust_hdb_model                               4.00   \n",
       "\n",
       "    clustering__n_clusters  clustering__min_cluster_size  \\\n",
       "35                     NaN                           5.0   \n",
       "25                     NaN                           5.0   \n",
       "27                     NaN                           5.0   \n",
       "28                     NaN                           5.0   \n",
       "33                     NaN                           5.0   \n",
       "\n",
       "    clustering__min_samples  \n",
       "35                      7.0  \n",
       "25                      7.0  \n",
       "27                      7.0  \n",
       "28                      7.0  \n",
       "33                     20.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values('silhouette_score', ascending=False).query(\"n_labels == 2\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc202bab",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "\n",
    "### Four Good Models\n",
    "Depending on needs there are four cluster analysis models which I recommend pursuing. \n",
    "We can pursue them as a basis for further modeling or use them for our business needs.\n",
    "- Model 29, a HDBSCAN model using a Robust Scaler produced 3 labels and a score of .659.\n",
    "- Model 24, a HDBSCAN model produced 4 labels and a score of .624\n",
    "- Model 35, a robust HDBSCAN model, produced 2 labels and a score .822\n",
    "- Model 25, a HDBSCAN model, produced 2 labels and a score .799\n",
    "\n",
    "All of these models are low-noise (<5%).\n",
    "\n",
    "All other models producing 2 labels were either similar to these in model character or significantly lower in score.\n",
    "There were model with greater than 2 labels which scored close to those models named above.\n",
    "\n",
    "#### Which of these 4 models to use?\n",
    "\n",
    "Either of the two 2 labels models is likely to be similar in application.\n",
    "Between these two, the higher scoring model 35 should be used.\n",
    "Both merit further exploration as a basis for improvement.\n",
    "However, 2 is a small number of models and the score likely benefits from simplicity.\n",
    "Having more labels, as in models 29 and 24, may provide more useful information even if it is less certain.\n",
    "Model 24, with 4 labels and a score nearly as high as model 29 (3 labels) is a standout.\n",
    "_I would recommend model 24 as the first candidate for use and further exploration_.\n",
    "\n",
    "Finally, we should explore ensemble usage. Especially, since the silhouette scores are high,\n",
    "combining a two label model and another model--creating 6 and 8 clusters, respectively--may\n",
    "provide further insight.\n",
    "\n",
    "### Process Assessment\n",
    "\n",
    "We tuned a large range of hyperparameters to find the above models.\n",
    "It is noteworthy that seemingly adjacent models in the parameter space sometimes diverged in scores.\n",
    "I have encountered many cases with structured data models where this hyperparameter tuning produced no benefit beyond chance differences.\n",
    "That was not the result here.\n",
    "Models 24 and 29 are standouts; there was no photo finish for these models.\n",
    "Further investigations with a more granular hyperparameter space are strongly recommended.\n",
    "Additionally, more careful consideration of hyperparameter effects is recommended.\n",
    "These models fit to this data quickly and there is little concern that more exploration would be too computationally expensive.\n",
    "Along these lines, investigation of DBSCAN and other clustering models is also recommended. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa3c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
