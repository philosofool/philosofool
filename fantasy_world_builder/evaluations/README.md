# Evaluations

Fundamentally, we're learning about and developing useful tools for evaluating
LLM applications.
Much of the point of this exercise is to figure how we can determine when the LLM
and AI that binds it does well.

Hence, with this package (for the time being) we include a number of evaluation tools.

These tests are _measurements_ of performance.
They help to assess if a application of an LLM or other AI is working well.
Working well is a matter of degree.